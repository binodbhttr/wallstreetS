{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9de5b4-9bea-4099-9631-f41c6d341c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Mean fluctuation is 0.09373796085309273\n",
      "Median fluctuation is 0.11190944459826124\n",
      "Standara Deviation of the fluctuation is 1.7604728928254403\n"
     ]
    }
   ],
   "source": [
    "#Welcome to Alpha Vantage! Your API key is: 6NY98HFWJ7HOKS8D. Please record this API key at a safe place for future data access.\n",
    "\n",
    "# Import yfinance \n",
    "import numpy as np\n",
    "import yfinance as yf   \n",
    " \n",
    "# Get the data for the stock Apple by specifying the stock ticker, start date, and end date \n",
    "data = yf.download('AAPL','2020-01-01','2023-1-2') \n",
    " \n",
    "#data = yf.download(tickers='AAPL', period='1d', interval='1m') #to download 1 day recent data\n",
    "# Plot the close prices \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#data.High.plot() \n",
    "\n",
    "x=np.array(data.Close)\n",
    "y=np.array(data.Open)\n",
    "\n",
    "delta=data.Close-data.Open\n",
    "\n",
    "d=(np.array(delta)/data.Open)*100\n",
    "\n",
    "print(\"Mean fluctuation is\",np.mean(d))\n",
    "print(\"Median fluctuation is\",np.median(d))\n",
    "print(\"Standara Deviation of the fluctuation is\",np.std(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df3bcae7-d950-4dd9-8b9e-1bd28a4acae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n",
      "[86.5079415  86.62490778]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "## Data (Apple stock prices)\n",
    "apple = x\n",
    "n = len(apple)\n",
    "print(n)\n",
    "## One-liner\n",
    "model = LinearRegression().fit(np.arange(n).reshape((n,1)), apple)\n",
    "\n",
    "## Result & puzzle\n",
    "print(model.predict([[3],[4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d817026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = yf.download('AAPL','2022-01-01','2023-1-2') \n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "X = df[['Open', 'High', 'Low', 'Volume']]\n",
    "y = df['Close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b705d2e5-daaf-4a36-9e19-e00c87203145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[127.14300003]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Select the features and target\n",
    "#X = df[['open', 'high', 'low', 'volume']]\n",
    "#y = df['close']\n",
    "\n",
    "# Create a random forest regressor and train it on the data\n",
    "regr = RandomForestRegressor(n_estimators=10)\n",
    "regr.fit(X, y)\n",
    "\n",
    "# Make a prediction on a new sample\n",
    "prediction = regr.predict([[100, 105, 95, 10000]])\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccbf489",
   "metadata": {},
   "source": [
    "# Using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9c1812-259c-46cb-abc3-8d868ac2836a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 3ms/step - loss: 24330.4180\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24309.9746\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24289.5605\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 24269.2598\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 24248.8203\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24228.5352\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24208.1621\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24187.8652\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24167.5430\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24147.2734\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 24126.9570\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 24106.7246\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 24086.3945\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 24066.1758\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 24045.9355\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 24025.6758\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 24005.4629\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23985.3027\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23965.1055\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23944.9551\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23924.8242\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23904.7109\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23884.6543\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23864.5176\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23844.4395\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23824.4043\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23804.4004\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23784.2969\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23764.2246\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23744.1426\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23724.0645\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23704.0332\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23684.0371\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23663.9375\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23643.9141\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23623.9141\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23603.8691\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23583.9355\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23563.9199\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23544.0098\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23524.0605\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23504.1250\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23484.3047\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23464.3828\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23444.5645\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23424.6621\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23404.9121\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23385.0098\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23365.2383\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23345.3926\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23325.5977\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23305.8242\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23286.1094\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23266.3984\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23246.6875\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23227.0508\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23207.3906\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23187.7383\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23168.0098\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23148.2773\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23128.6191\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23108.8848\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23089.1875\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23069.5117\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23049.8809\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23030.2656\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 23010.6875\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22991.0566\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22971.4629\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22951.8945\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 22932.2773\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22912.7734\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 22893.2344\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 22873.7559\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22854.2676\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22834.7832\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22815.2871\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 22795.8320\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22776.3008\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22756.9434\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22737.5000\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22718.1777\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22698.8047\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22679.4004\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22660.0801\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22640.6777\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22621.3066\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22601.9141\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22582.4980\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22563.1367\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22543.8496\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22524.5293\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22505.2246\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22485.9766\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22466.6797\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22447.4668\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22428.0898\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22408.8906\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22389.6309\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22370.4492\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22531.7422\n",
      "Test loss: 22531.7422\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "[[5.758441]]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df[['Open', 'High', 'Low', 'Volume']].values\n",
    "y = df['Close'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for the RNN\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(1, X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test loss: {score:.4f}')\n",
    "\n",
    "# Make a prediction on a new sample\n",
    "prediction = model.predict(np.array([[100, 105, 95, 10000]]).reshape(1, 1, 4))\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9a51f947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.72779999e+02 1.73710007e+02 1.71660004e+02 5.63771000e+07]]\n",
      "\n",
      " [[1.72320007e+02 1.75179993e+02 1.70820007e+02 7.61383000e+07]]\n",
      "\n",
      " [[1.61149994e+02 1.62899994e+02 1.59820007e+02 7.33140000e+07]]\n",
      "\n",
      " [[1.78550003e+02 1.79610001e+02 1.76699997e+02 9.26332000e+07]]\n",
      "\n",
      " [[1.34289993e+02 1.37339996e+02 1.32160004e+02 9.15330000e+07]]\n",
      "\n",
      " [[1.51190002e+02 1.51470001e+02 1.48559998e+02 9.60299000e+07]]\n",
      "\n",
      " [[1.41070007e+02 1.42899994e+02 1.40270004e+02 8.52509000e+07]]\n",
      "\n",
      " [[1.29669998e+02 1.31029999e+02 1.25870003e+02 8.54384000e+07]]\n",
      "\n",
      " [[1.71339996e+02 1.73779999e+02 1.71089996e+02 8.04408000e+07]]\n",
      "\n",
      " [[1.36820007e+02 1.38589996e+02 1.35630005e+02 7.24338000e+07]]\n",
      "\n",
      " [[1.54789993e+02 1.57100006e+02 1.53610001e+02 8.79654000e+07]]\n",
      "\n",
      " [[1.45820007e+02 1.50009995e+02 1.44369995e+02 9.39797000e+07]]\n",
      "\n",
      " [[1.52220001e+02 1.53589996e+02 1.48559998e+02 8.98683000e+07]]\n",
      "\n",
      " [[1.54009995e+02 1.55039993e+02 1.52279999e+02 5.36239000e+07]]\n",
      "\n",
      " [[1.71779999e+02 1.71779999e+02 1.69199997e+02 7.65755000e+07]]\n",
      "\n",
      " [[1.49449997e+02 1.51830002e+02 1.49339996e+02 5.83014000e+07]]\n",
      "\n",
      " [[1.39130005e+02 1.40360001e+02 1.38160004e+02 7.04337000e+07]]\n",
      "\n",
      " [[1.58979996e+02 1.62759995e+02 1.57020004e+02 1.15798400e+08]]\n",
      "\n",
      " [[1.42699997e+02 1.43490005e+02 1.40970001e+02 7.02079000e+07]]\n",
      "\n",
      " [[1.72860001e+02 1.73949997e+02 1.70949997e+02 7.72512000e+07]]\n",
      "\n",
      " [[1.36690002e+02 1.37649994e+02 1.33729996e+02 1.60156900e+08]]\n",
      "\n",
      " [[1.70160004e+02 1.75000000e+02 1.69509995e+02 1.15541600e+08]]\n",
      "\n",
      " [[1.30070007e+02 1.33080002e+02 1.29809998e+02 1.34520300e+08]]\n",
      "\n",
      " [[1.68710007e+02 1.69029999e+02 1.65500000e+02 7.22467000e+07]]\n",
      "\n",
      " [[1.51210007e+02 1.51350006e+02 1.48369995e+02 1.62278800e+08]]\n",
      "\n",
      " [[1.61479996e+02 1.63410004e+02 1.59410004e+02 9.14549000e+07]]\n",
      "\n",
      " [[1.67990005e+02 1.72639999e+02 1.67649994e+02 9.80627000e+07]]\n",
      "\n",
      " [[1.71509995e+02 1.72539993e+02 1.69410004e+02 9.09567000e+07]]\n",
      "\n",
      " [[1.70970001e+02 1.72949997e+02 1.70250000e+02 6.25274000e+07]]\n",
      "\n",
      " [[1.42190002e+02 1.43369995e+02 1.40000000e+02 6.97211000e+07]]\n",
      "\n",
      " [[1.42699997e+02 1.44500000e+02 1.41059998e+02 7.04627000e+07]]\n",
      "\n",
      " [[1.69820007e+02 1.70539993e+02 1.66190002e+02 8.27727000e+07]]\n",
      "\n",
      " [[1.49130005e+02 1.49869995e+02 1.47289993e+02 6.42183000e+07]]\n",
      "\n",
      " [[1.34990005e+02 1.43589996e+02 1.34369995e+02 1.13224000e+08]]\n",
      "\n",
      " [[1.71729996e+02 1.75350006e+02 1.71429993e+02 7.48292000e+07]]\n",
      "\n",
      " [[1.41350006e+02 1.44119995e+02 1.41080002e+02 7.40643000e+07]]\n",
      "\n",
      " [[1.65710007e+02 1.70350006e+02 1.62800003e+02 1.79935700e+08]]\n",
      "\n",
      " [[1.65020004e+02 1.67820007e+02 1.63910004e+02 6.77238000e+07]]\n",
      "\n",
      " [[1.44080002e+02 1.48949997e+02 1.43250000e+02 7.81407000e+07]]\n",
      "\n",
      " [[1.56710007e+02 1.58229996e+02 1.53270004e+02 1.23055300e+08]]\n",
      "\n",
      " [[1.39899994e+02 1.41910004e+02 1.39770004e+02 8.91168000e+07]]\n",
      "\n",
      " [[1.37789993e+02 1.43259995e+02 1.37649994e+02 1.17726300e+08]]\n",
      "\n",
      " [[1.55910004e+02 1.59789993e+02 1.55380005e+02 8.80632000e+07]]\n",
      "\n",
      " [[1.59669998e+02 1.66479996e+02 1.59259995e+02 1.08256500e+08]]\n",
      "\n",
      " [[1.42539993e+02 1.43100006e+02 1.39449997e+02 8.59256000e+07]]\n",
      "\n",
      " [[1.63500000e+02 1.64389999e+02 1.57820007e+02 1.08275300e+08]]\n",
      "\n",
      " [[1.56009995e+02 1.59440002e+02 1.54179993e+02 1.16124600e+08]]\n",
      "\n",
      " [[1.36039993e+02 1.39039993e+02 1.35660004e+02 7.10516000e+07]]\n",
      "\n",
      " [[1.52380005e+02 1.54470001e+02 1.50910004e+02 8.66525000e+07]]\n",
      "\n",
      " [[1.63059998e+02 1.65419998e+02 1.62429993e+02 9.50566000e+07]]\n",
      "\n",
      " [[1.59589996e+02 1.64259995e+02 1.59300003e+02 1.04956000e+08]]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c024cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4db4247e62966fd47bff2e1e1fec92dd62ed5848882e33f50cf37de94d0c3760"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
